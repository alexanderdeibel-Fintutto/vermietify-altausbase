import { createClientFromRequest } from 'npm:@base44/sdk@0.8.6';

Deno.serve(async (req) => {
    const base44 = createClientFromRequest(req);
    
    try {
        const user = await base44.auth.me();
        if (!user || user.role !== 'admin') {
            return Response.json({ error: 'Unauthorized' }, { status: 401 });
        }

        const startTime = Date.now();

        // Sammle echte Statistiken aus der Datenbank
        const buildings = await base44.asServiceRole.entities.Building.list();
        const units = await base44.asServiceRole.entities.Unit.list();
        const contracts = await base44.asServiceRole.entities.LeaseContract.list();
        const documents = await base44.asServiceRole.entities.Document.list();

        const markdown = `# Performance-Metriken & System-Limits

**Generiert am:** ${new Date().toISOString()}

## Aktuelle System-Auslastung

### Datenbankgr√∂√üe (Stand heute)
- **Geb√§ude:** ${buildings.length} Eintr√§ge
- **Einheiten:** ${units.length} Eintr√§ge
- **Mietvertr√§ge:** ${contracts.length} Eintr√§ge
- **Dokumente:** ${documents.length} Eintr√§ge
- **Gesch√§tzte DB-Gr√∂√üe:** ~${Math.round((buildings.length * 2 + units.length * 1.5 + contracts.length * 3 + documents.length * 5) / 1024)} MB

### Typische Datenmengen pro Kunde
- **Klein:** 1-5 Objekte, 10-50 Einheiten, 20-100 Vertr√§ge
- **Mittel:** 5-20 Objekte, 50-200 Einheiten, 100-500 Vertr√§ge
- **Gro√ü:** 20-100 Objekte, 200-1000 Einheiten, 500-2000 Vertr√§ge
- **Enterprise:** 100+ Objekte, 1000+ Einheiten, 2000+ Vertr√§ge

## Performance-kritische Operationen

### Sehr schnell (<100ms)
- ‚úÖ Einzelnes Objekt laden
- ‚úÖ Mieter-Dashboard anzeigen
- ‚úÖ Dokument-Vorschau
- ‚úÖ Einfache Listen (bis 50 Eintr√§ge)

### Schnell (100-500ms)
- ‚ö° Dashboard mit allen KPIs
- ‚ö° Objekt-Detailseite mit allen Verkn√ºpfungen
- ‚ö° Betriebskosten-Abrechnung generieren (Standard-Objekt)
- ‚ö° PDF-Dokument erstellen (1-3 Seiten)

### Mittel (500ms-2s)
- üîÑ Liste aller Transaktionen (100-500 Eintr√§ge)
- üîÑ Komplexe Filter-Operationen
- üîÑ Anlage V generieren
- üîÑ Bulk-Import CSV (50-200 Zeilen)

### Langsam (2-10s)
- ‚è≥ Betriebskosten-Abrechnung f√ºr gro√üe Objekte (100+ Einheiten)
- ‚è≥ Jahres√ºbersicht alle Objekte
- ‚è≥ Bulk-Operations (1000+ Datens√§tze)
- ‚è≥ Komplexe Reports mit vielen Aggregationen

### Sehr langsam (>10s)
- ‚è≤Ô∏è Vollst√§ndiger Daten-Export (alle Objekte)
- ‚è≤Ô∏è KI-gest√ºtzte Analyse √ºber gesamten Datenbestand
- ‚è≤Ô∏è Historische Trends (5+ Jahre Daten)

## System-Limits & Schwellenwerte

### Datei-Upload
- **Max. Dateigr√∂√üe einzeln:** 50 MB
- **Max. Dateigr√∂√üe pro Request:** 100 MB
- **Empfohlene Dateigr√∂√üe:** <10 MB
- **Unterst√ºtzte Formate:** PDF, JPG, PNG, CSV, XLSX

### Datens√§tze
- **Max. Objekte pro Account:** 10.000 (technisch unbegrenzt)
- **Max. Einheiten pro Objekt:** 1.000 (empfohlen: <200)
- **Max. Vertr√§ge pro Einheit:** 100 (Historie)
- **Max. Belege pro Monat:** 10.000

### Listen & Pagination
- **Standard Page Size:** 50 Eintr√§ge
- **Max. Page Size:** 500 Eintr√§ge
- **Empfohlen bei gro√üen Datenmengen:** Server-seitige Pagination + Filter

### API Rate Limits
- **Standard User:** 1000 Requests / Stunde
- **Admin User:** 5000 Requests / Stunde
- **Burst Limit:** 50 Requests / Minute

### Concurrent Users
- **Optimal:** 1-10 gleichzeitige Nutzer
- **Gut:** 10-50 gleichzeitige Nutzer
- **Grenze:** 100 gleichzeitige Nutzer
- **√úber 100:** Performance-Degradation m√∂glich

## Performance-Optimierungsstrategien

### 1. Pagination & Lazy Loading
\`\`\`javascript
// ‚ùå Schlecht: Alle laden
const allContracts = await loadAllContracts();

// ‚úÖ Gut: Paginiert laden
const page1 = await loadContracts({ page: 1, limit: 50 });
\`\`\`

### 2. Selective Loading
\`\`\`javascript
// ‚ùå Schlecht: Alles laden
const building = await loadBuildingWithEverything(id);

// ‚úÖ Gut: Nur was ben√∂tigt wird
const building = await loadBuilding(id);
const units = await loadUnits({ building_id: id });
\`\`\`

### 3. Caching
- **Browser-Cache:** Static Assets (24h)
- **API-Cache:** Listen-Daten (5 min)
- **Session-Cache:** User-Daten (bis Logout)

### 4. Debouncing & Throttling
\`\`\`javascript
// ‚úÖ Such-Eingabe debounced (300ms)
const debouncedSearch = debounce(searchFunction, 300);
\`\`\`

### 5. Background Jobs
- ‚úÖ Betriebskosten-Generierung (asynchron)
- ‚úÖ PDF-Erstellung (Queue)
- ‚úÖ E-Mail-Versand (Batch)

## Bottlenecks & Problembereiche

### üî¥ Kritisch
1. **Betriebskosten-Abrechnung bei 100+ Einheiten**
   - Problem: Zu viele Berechnungen auf einmal
   - L√∂sung: Batch-Processing, Progress-Indicator

2. **Dashboard mit 1000+ Objekten**
   - Problem: Zu viele DB-Queries
   - L√∂sung: Aggregationen auf DB-Ebene

### üü° Verbesserungsw√ºrdig
1. **PDF-Generierung**
   - Aktuell: 2-5s f√ºr 10 Seiten
   - Ziel: <1s

2. **Volltext-Suche**
   - Aktuell: 500ms-1s
   - Ziel: <200ms (Elastic Search)

### üü¢ Gut optimiert
- Objekt-Listen
- Mieter-Dashboard
- Dokument-Vorschau
- Einfache CRUD-Operationen

## Monitoring & Metriken

### Key Performance Indicators (KPIs)
- **Average Response Time:** <500ms (Ziel)
- **P95 Response Time:** <2s
- **Error Rate:** <1%
- **Uptime:** >99.5%

### Zu √ºberwachende Metriken
1. **Response Times** - pro Endpoint
2. **Database Query Times** - langsame Queries identifizieren
3. **Memory Usage** - Memory Leaks vermeiden
4. **CPU Usage** - Spitzen erkennen
5. **Concurrent Users** - Skalierung planen

## Skalierungs-Strategien

### Kurzfristig (bis 100 Nutzer)
- ‚úÖ Vertikale Skalierung (mehr RAM/CPU)
- ‚úÖ Database Indexing optimieren
- ‚úÖ Caching Layer einf√ºhren

### Mittelfristig (100-500 Nutzer)
- üîÑ Horizontale Skalierung (Load Balancer)
- üîÑ Read-Replicas f√ºr Datenbank
- üîÑ CDN f√ºr Static Assets

### Langfristig (>500 Nutzer)
- üöÄ Microservices-Architektur
- üöÄ Sharding der Datenbank
- üöÄ Geo-Distributed Setup
`;

        const duration = (Date.now() - startTime) / 1000;
        const fileSize = new TextEncoder().encode(markdown).length;

        const existingDocs = await base44.asServiceRole.entities.GeneratedDocumentation.filter({
            documentation_type: 'performance_data'
        });

        const docData = {
            documentation_type: 'performance_data',
            title: 'Performance-Metriken & Limits',
            description: 'Typische Datenmengen, Performance-kritische Operationen, System-Limits und Optimierungs-Strategien',
            content_markdown: markdown,
            content_json: {
                generated_at: new Date().toISOString(),
                current_stats: {
                    buildings: buildings.length,
                    units: units.length,
                    contracts: contracts.length,
                    documents: documents.length
                }
            },
            file_size_bytes: fileSize,
            generation_duration_seconds: duration,
            last_generated_at: new Date().toISOString(),
            status: 'completed'
        };

        if (existingDocs.length > 0) {
            await base44.asServiceRole.entities.GeneratedDocumentation.update(existingDocs[0].id, docData);
        } else {
            await base44.asServiceRole.entities.GeneratedDocumentation.create(docData);
        }

        return Response.json({
            success: true,
            documentation_type: 'performance_data',
            duration,
            size: fileSize
        });

    } catch (error) {
        console.error('Performance documentation generation error:', error);
        return Response.json({
            error: 'Generation failed',
            details: error.message
        }, { status: 500 });
    }
});